{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import zuko\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "\n",
    "sns.set(style=\"white\", context=\"notebook\", palette=\"deep\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/uav_data\"\n",
    "elevator_failure_experiments = [\n",
    "    \"carbonZ_2018-09-11-14-41-51_elevator_failure\",\n",
    "    \"carbonZ_2018-09-11-15-05-11_1_elevator_failure\",\n",
    "]\n",
    "rudder_failure_experiments = [\n",
    "    \"carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\",\n",
    "    \"carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\",\n",
    "    \"carbonZ_2018-09-11-15-06-34_3_rudder_left_failure\",\n",
    "]\n",
    "nominal_experiments = [\n",
    "    \"carbonZ_2018-07-18-16-37-39_1_no_failure\",\n",
    "    \"carbonZ_2018-07-30-16-39-00_3_no_failure\",\n",
    "    \"carbonZ_2018-09-11-14-16-55_no_failure\",\n",
    "    \"carbonZ_2018-09-11-14-41-38_no_failure\",\n",
    "    \"carbonZ_2018-09-11-15-05-11_2_no_failure\",\n",
    "    \"carbonZ_2018-10-05-14-34-20_1_no_failure\",\n",
    "    \"carbonZ_2018-10-05-14-37-22_1_no_failure\",\n",
    "    \"carbonZ_2018-10-05-15-52-12_1_no_failure\",\n",
    "    \"carbonZ_2018-10-05-15-52-12_2_no_failure\",\n",
    "    \"carbonZ_2018-10-18-11-08-24_no_failure\",\n",
    "]\n",
    "fields = {\n",
    "    \"mavros-local_position-velocity\": {\n",
    "        \"field.twist.linear.x\": \"twist_vx\",\n",
    "        \"field.twist.linear.y\": \"twist_vy\",\n",
    "        \"field.twist.linear.z\": \"twist_vz\",\n",
    "        \"field.twist.angular.x\": \"twist_wx\",\n",
    "        \"field.twist.angular.y\": \"twist_wy\",\n",
    "        \"field.twist.angular.z\": \"twist_wz\",\n",
    "    },\n",
    "    \"mavros-nav_info-pitch\": {\n",
    "        \"field.commanded\": \"pitch_commanded\",\n",
    "        \"field.measured\": \"pitch_measured\",\n",
    "    },\n",
    "    \"mavros-nav_info-roll\": {\n",
    "        \"field.commanded\": \"roll_commanded\",\n",
    "        \"field.measured\": \"roll_measured\",\n",
    "    },\n",
    "    \"mavros-nav_info-yaw\": {\n",
    "        \"field.commanded\": \"yaw_commanded\",\n",
    "        \"field.measured\": \"yaw_measured\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(base_path, experiment_path, fields, dt=0.25):\n",
    "    # Load all the dfs into a list, remapping columns to the names in field_names\n",
    "    dfs = []\n",
    "    for field_name, field_map in fields.items():\n",
    "        path = os.path.join(\n",
    "            base_path, experiment_path, experiment_path + \"-\" + field_name + \".csv\"\n",
    "        )\n",
    "        df = pd.read_csv(path)\n",
    "        df.rename(columns=field_map, inplace=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Get the min and max times\n",
    "    min_time = min([df[\"%time\"].min() for df in dfs]) * 1e-9\n",
    "    max_time = max([df[\"%time\"].max() for df in dfs]) * 1e-9\n",
    "\n",
    "    # Normalize and resample time\n",
    "    dt = 0.25\n",
    "    t = np.arange(0, max_time - min_time, dt)\n",
    "    normalized_dfs = []\n",
    "    for df, field_map in zip(dfs, fields.values()):\n",
    "        sampled_times = df[\"%time\"] * 1e-9 - min_time\n",
    "        normalized_df = pd.DataFrame(index=t, columns=field_map.values())\n",
    "        normalized_df.index.name = \"Time (s)\"\n",
    "\n",
    "        for field in field_map.values():\n",
    "            # We have to treat the error status specially, since it's only reported\n",
    "            # when a failure is occuring (and is implicitly zero otherwise)\n",
    "            if \"status\" in field:\n",
    "                normalized_df[field] = np.interp(t, sampled_times, df[field], left=0)\n",
    "            else:\n",
    "                normalized_df[field] = np.interp(t, sampled_times, df[field])\n",
    "\n",
    "            # Handle angles to unwrap them\n",
    "            if \"roll\" in field or \"pitch\" in field or \"yaw\" in field:\n",
    "                normalized_df[field] = np.unwrap(normalized_df[field], period=360)\n",
    "\n",
    "        normalized_dfs.append(normalized_df)\n",
    "\n",
    "    # Merge all the dataframes into one\n",
    "    df = pd.concat(normalized_dfs, axis=1, join=\"inner\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load the data\n",
    "nominal_dfs = [\n",
    "    load_data(os.path.join(base_path, \"nominal\"), experiment_path, fields, dt=0.25)\n",
    "    for experiment_path in nominal_experiments\n",
    "]\n",
    "elevator_failure_dfs = [\n",
    "    load_data(\n",
    "        os.path.join(base_path, \"failure\"),\n",
    "        experiment_path,\n",
    "        fields | {\"failure_status-elevator\": {\"field.data\": \"elevator_status\"}},\n",
    "        dt=0.25,\n",
    "    )\n",
    "    for experiment_path in elevator_failure_experiments\n",
    "]\n",
    "rudder_failure_dfs = [\n",
    "    load_data(\n",
    "        os.path.join(base_path, \"failure\"),\n",
    "        experiment_path,\n",
    "        fields | {\"failure_status-rudder\": {\"field.data\": \"rudder_status\"}},\n",
    "        dt=0.25,\n",
    "    )\n",
    "    for experiment_path in rudder_failure_experiments\n",
    "]\n",
    "\n",
    "\n",
    "# Convert the list of DFs into couple of lists of tensors\n",
    "def df_to_tensors(df):\n",
    "    roll = df[\"roll_measured\"].to_numpy() * np.pi / 180\n",
    "    pitch = df[\"pitch_measured\"].to_numpy() * np.pi / 180\n",
    "    yaw = df[\"yaw_measured\"].to_numpy() * np.pi / 180\n",
    "\n",
    "    roll_desired = df[\"roll_commanded\"].to_numpy() * np.pi / 180\n",
    "    pitch_desired = df[\"pitch_commanded\"].to_numpy() * np.pi / 180\n",
    "    yaw_desired = df[\"yaw_commanded\"].to_numpy() * np.pi / 180\n",
    "\n",
    "    p = df[\"twist_wx\"].to_numpy()\n",
    "    q = -df[\"twist_wy\"].to_numpy()\n",
    "    r = -df[\"twist_wz\"].to_numpy()\n",
    "\n",
    "    states = torch.tensor(\n",
    "        np.stack([roll, pitch, yaw], axis=1),\n",
    "        dtype=torch.float32,\n",
    "        device=device,\n",
    "    )\n",
    "    initial_states = states[0]\n",
    "    pqr = torch.tensor(\n",
    "        np.stack([p, q, r], axis=1),\n",
    "        dtype=torch.float32,\n",
    "        device=device,\n",
    "    )\n",
    "    desired_states = torch.tensor(\n",
    "        np.stack([roll_desired, pitch_desired, yaw_desired], axis=1),\n",
    "        dtype=torch.float32,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    return initial_states, states, pqr, desired_states\n",
    "\n",
    "\n",
    "nominal_data = [df_to_tensors(df) for df in nominal_dfs]\n",
    "nominal_data = tuple(map(list, zip(*nominal_data)))\n",
    "(\n",
    "    nominal_initial_states,\n",
    "    nominal_observed_states,\n",
    "    nominal_observed_pqr,\n",
    "    nominal_commands,\n",
    ") = nominal_data\n",
    "\n",
    "elevator_failure_data = [df_to_tensors(df) for df in elevator_failure_dfs]\n",
    "elevator_failure_data = tuple(map(list, zip(*elevator_failure_data)))\n",
    "(\n",
    "    elevator_failure_initial_states,\n",
    "    elevator_failure_observed_states,\n",
    "    elevator_failure_observed_pqr,\n",
    "    elevator_failure_commands,\n",
    ") = elevator_failure_data\n",
    "\n",
    "rudder_failure_data = [df_to_tensors(df) for df in rudder_failure_dfs]\n",
    "rudder_failure_data = tuple(map(list, zip(*rudder_failure_data)))\n",
    "(\n",
    "    rudder_failure_initial_states,\n",
    "    rudder_failure_observed_states,\n",
    "    rudder_failure_observed_pqr,\n",
    "    rudder_failure_commands,\n",
    ") = rudder_failure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    initial_state,\n",
    "    commands,\n",
    "    observed_states=None,\n",
    "    observed_pqr=None,\n",
    "    dt=0.25,\n",
    "    observation_noise_scale=1e-1,\n",
    "):\n",
    "    \"\"\"Define a simplified model for the UAV attitude dynamics.\n",
    "\n",
    "    Args:\n",
    "        initial_state: List of initial states of the UAV for each run in the batch.\n",
    "        commands: List of commands to the UAV for each run in the batch.\n",
    "        observed_states: List of observed states of the UAV for each run in the batch.\n",
    "        observed_pqr: List of observed angular velocities  for each run in the batch.\n",
    "        dt: Time step.\n",
    "    \"\"\"\n",
    "    # Check consistency of batch and time dimensions\n",
    "    N = len(initial_state)\n",
    "    for i in range(N):\n",
    "        assert initial_state[i].shape[0] == 3\n",
    "        T = commands[i].shape[0]\n",
    "        assert commands[i].shape == (T, 3)\n",
    "        assert observed_pqr[i] is None or observed_pqr[i].shape == (T, 3)\n",
    "        assert observed_states[i] is None or observed_states[i].shape == (T, 3)\n",
    "\n",
    "    # Use attitude dyamics with state x = [phi, theta, psi] (roll, pitch, yaw)\n",
    "    # dx/dt = J^-1 * (Ax + Ke + d + eta)\n",
    "    # where J^-1 is the kinematics, A is the state-to-state transfer matrix, K is the\n",
    "    # error-to-state transfer matrix, e is the error, d is a constant bias, and eta is\n",
    "    # Gaussian noise.\n",
    "\n",
    "    # Sample the matrices from the prior\n",
    "    A = pyro.sample(\n",
    "        \"A\",\n",
    "        dist.Normal(torch.zeros(3, 3, device=device), torch.ones(3, 3, device=device)),\n",
    "    )\n",
    "    K = pyro.sample(\n",
    "        \"K\",\n",
    "        dist.Normal(torch.zeros(3, 3, device=device), torch.ones(3, 3, device=device)),\n",
    "    )\n",
    "    d = pyro.sample(\n",
    "        \"d\", dist.Normal(torch.zeros(3, device=device), torch.ones(3, device=device))\n",
    "    ).reshape(3, 1)\n",
    "    log_noise_strength = pyro.sample(\n",
    "        \"log_noise_strength\", dist.Normal(torch.tensor(-2.0, device=device), 1.0)\n",
    "    )\n",
    "    noise_strength = torch.exp(log_noise_strength)\n",
    "\n",
    "    # Start the simulation with an initial state\n",
    "    Ts = [x.shape[0] for x in commands]\n",
    "    states = [torch.zeros(T, 3, device=device) for T in Ts]\n",
    "    state_observation_noise = [torch.zeros(T, 3, device=device) for T in Ts]\n",
    "    pqrs = [torch.zeros(T, 3, device=device) for T in Ts]\n",
    "    action_noise_trajectory = [torch.zeros(T, 3, device=device) for T in Ts]\n",
    "\n",
    "    for i in range(N):\n",
    "        for t in range(1, T + 1):\n",
    "            state = states[i][t - 1].reshape(3, 1)\n",
    "            command = commands[i][t - 1].reshape(3, 1)\n",
    "\n",
    "            # Compute the error\n",
    "            e = command - state\n",
    "\n",
    "            # Get the mean velocity based on the system matrices\n",
    "            pqr_mean = A @ state + K @ e + d\n",
    "            pqrs[i][t - 1] = pqr_mean.reshape(3)\n",
    "            # Add noise\n",
    "            pqr = pyro.sample(\n",
    "                f\"pqr_{i}_t{t}\",\n",
    "                dist.Normal(\n",
    "                    pqr_mean, noise_strength * torch.ones_like(pqr_mean)\n",
    "                ).to_event(2),\n",
    "                obs=observed_pqr[i][t - 1].reshape(-1, 3, 1)\n",
    "                if observed_pqr[i] is not None\n",
    "                else None,\n",
    "            )\n",
    "            action_noise_trajectory[i][t - 1] = (pqr - pqr_mean).reshape(3)\n",
    "\n",
    "            # Only update the dynamics if we're not on the last step\n",
    "            if t == T:\n",
    "                continue\n",
    "\n",
    "            # Construct the kinematic matrix\n",
    "            roll, pitch = state[0], state[1]\n",
    "            Jinv = torch.zeros(3, 3, device=device)\n",
    "            Jinv[0, 0] = 1.0\n",
    "            Jinv[0, 1] = torch.tan(pitch) * torch.sin(roll)\n",
    "            Jinv[0, 2] = torch.tan(roll) * torch.cos(pitch)\n",
    "            Jinv[1, 1] = torch.cos(roll)\n",
    "            Jinv[1, 2] = -torch.sin(roll)\n",
    "            Jinv[2, 1] = torch.sin(roll) / torch.cos(pitch)\n",
    "            Jinv[2, 2] = torch.cos(roll) / torch.cos(pitch)\n",
    "\n",
    "            # Integrate the change in state\n",
    "            next_state = state + dt * Jinv @ pqr\n",
    "            states[i][t] = next_state.reshape(3)\n",
    "            observed_state = pyro.sample(\n",
    "                f\"state_{i}_t{t}\",\n",
    "                dist.Normal(\n",
    "                    next_state, observation_noise_scale * torch.ones_like(next_state)\n",
    "                ).to_event(1),\n",
    "                obs=observed_states[i][t].reshape(next_state.shape)\n",
    "                if observed_states[i] is not None\n",
    "                else None,\n",
    "            )\n",
    "            state_observation_noise[i][t] = (observed_state - next_state).reshape(3)\n",
    "\n",
    "    return states, pqrs, state_observation_noise, action_noise_trajectory\n",
    "\n",
    "\n",
    "# Try the model on the nominal data\n",
    "sim_states, sim_pqrs, sim_obs_noise, sim_action_noise = model(\n",
    "    nominal_initial_states,\n",
    "    nominal_commands,\n",
    "    [None] * len(nominal_commands),  # nominal_observed_states,\n",
    "    [None] * len(nominal_commands),  # nominal_observed_pqr,\n",
    "    dt=0.25,\n",
    "    observation_noise_scale=1e-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "def elbo_loss(model, guide, context, num_particles=10, *model_args, **model_kwargs):\n",
    "    elbo = torch.tensor(0.0).to(context.device)\n",
    "    guide_dist = guide(context)\n",
    "    for _ in range(num_particles):\n",
    "        posterior_sample, posterior_logprob = guide_dist.rsample_and_log_prob()\n",
    "\n",
    "        # Parse the sample into the correct shapes\n",
    "        A = posterior_sample[:9].reshape(3, 3)\n",
    "        K = posterior_sample[9:18].reshape(3, 3)\n",
    "        d = posterior_sample[18:21].reshape(3)\n",
    "        log_noise_strength = posterior_sample[21]\n",
    "\n",
    "        model_trace = pyro.poutine.trace(\n",
    "            pyro.poutine.condition(\n",
    "                model,\n",
    "                data={\n",
    "                    \"A\": A,\n",
    "                    \"K\": K,\n",
    "                    \"d\": d,\n",
    "                    \"log_noise_strength\": log_noise_strength,\n",
    "                },\n",
    "            )\n",
    "        ).get_trace(*model_args, **model_kwargs)\n",
    "        model_logprob = model_trace.log_prob_sum()\n",
    "\n",
    "        elbo += (model_logprob - posterior_logprob) / num_particles\n",
    "\n",
    "    return -elbo  #  negative to make it a loss\n",
    "\n",
    "\n",
    "def kl_divergence(p, q, p_contexts, q_contexts, num_particles=10):\n",
    "    # Make sure contexts have a batch dimension\n",
    "    if p_contexts.ndim == 1:\n",
    "        p_contexts = p_contexts.unsqueeze(0)\n",
    "\n",
    "    if q_contexts.ndim == 1:\n",
    "        q_contexts = q_contexts.unsqueeze(0)\n",
    "\n",
    "    # Make sure contexts have the same shape\n",
    "    if p_contexts.shape != q_contexts.shape:\n",
    "        raise ValueError(\"Contexts must have the same shape\")\n",
    "\n",
    "    p_dist = p(p_contexts)\n",
    "    q_dist = q(q_contexts)\n",
    "\n",
    "    p_samples, p_logprobs = p_dist.rsample_and_log_prob((num_particles,))\n",
    "    q_logprobs = q_dist.log_prob(p_samples)\n",
    "\n",
    "    kl_divergence = (p_logprobs - q_logprobs).mean(dim=0)\n",
    "\n",
    "    return kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ELBO function\n",
    "with torch.no_grad():\n",
    "    flow = zuko.flows.NSF(\n",
    "        features=2 * 3 * 3 + 3 + 1,\n",
    "        context=1,\n",
    "        transforms=2,\n",
    "        hidden_features=(16, 16),\n",
    "    ).to(device)\n",
    "    context = torch.tensor([0.0], device=device)\n",
    "    print(\n",
    "        elbo_loss(\n",
    "            model,\n",
    "            flow,\n",
    "            context,\n",
    "            10,\n",
    "            initial_state=nominal_initial_states,\n",
    "            commands=nominal_commands,\n",
    "            observed_states=nominal_observed_states,\n",
    "            observed_pqr=nominal_observed_pqr,\n",
    "            dt=0.25,\n",
    "            observation_noise_scale=1e-1,\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
